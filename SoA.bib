Automatically generated by Mendeley Desktop 1.19.1
Any changes to this file will be lost if it is regenerated by Mendeley.

BibTeX export options can be customized via Options -> BibTeX in Mendeley Desktop

@article{Chaudhary2012,
abstract = {Lung cancer seems to be the common cause of death among people throughout the world. Early detection of lung cancer can increase the chance of survival among people. The overall 5-year survival rate for lung cancer patients increases from 14 to 49{\%} if the disease is detected in time. Although Computed Tomography (CT) can be more efficient than X-ray. However, problem seemed to merge due to time constraint in detecting the present of lung cancer regarding on the several diagnosing method used. Hence, a lung cancer detection system using image processing is used to classify the present of lung cancer in an CT-images. In this study, MATLAB have been used through every procedures made. In image processing procedures, process such as image pre-processing, segmentation and feature extraction have been discussed in detail. We are aiming to get the more accurate results by using various enhancement and segmentation techniques.},
author = {Chaudhary, Anita and Singh, Sonit Sukhraj},
doi = {10.1109/ICCS.2012.43},
file = {::},
isbn = {978-1-4673-2647-6},
journal = {2012 International Conference on Computing Sciences},
keywords = {-ct,lcds,metastasis,morphologic,thresholding,watershed},
pages = {142--146},
title = {{Lung Cancer Detection on CT Images by Using Image Processing}},
url = {http://ieeexplore.ieee.org/document/6391662/},
year = {2012}
}
@article{Punithavathy2015,
author = {Punithavathy, K and Ramya, M.M. and Poobal, Sumathi},
doi = {10.1109/RACE.2015.7097244},
file = {::},
isbn = {978-8-1925-9743-0},
journal = {International Conference on Robotics, Automation, Control and Embedded Systems - RACE},
keywords = {automatic detection,ct,lung cancer,pet},
number = {February},
pages = {14--18},
title = {{Analysis of Statistical Texture Features for Automatic Lung Cancer Detection in PET / CT Images}},
year = {2015}
}
@article{LogeshKumar2016,
abstract = {The detection of lung cancer through image processing is an important tool for diagnoses. Different methods were employed to detect the cancerous cell of a lung with image pre processing such as Gabor filter, image segmentation using watershed segmentation and feature extraction by using MATLAB. In this experiment, various Computed Tomography (CT) images of lung were used as input image and obtained the output image in JPEG format. The resultant output of this technique was evaluated. Based on the results, it shows that watershed segmentation technique is showed better results than other segmentation techniques for lung cancer cell identification.},
author = {{Logesh Kumar}, S. and Swathy, M. and Sathish, S. and Sivaraman, J. and Rajasekar, M.},
doi = {10.17485/ijst/2016/v9i1/85765},
file = {::},
issn = {09745645},
journal = {Indian Journal of Science and Technology},
keywords = {CT lung cancer image,Image segmentation,Thresholding operation,Watershed method},
number = {1},
pages = {1--4},
title = {{Identification of lung cancer cell using watershed segmentation on CT images}},
volume = {9},
year = {2016}
}
@article{Khan2015,
author = {Khan, Daud Hossain and Ahmed, Mansur and Bach, Christian},
file = {::},
journal = {Journal of Biomedical Engineering and Medical Imaging},
keywords = {area,ct,lung cancer,matlab,region-of-interest,roi},
number = {6},
pages = {1--7},
title = {{Preliminary Detection and Analysis of Lung Cancer on CT images using MATLAB : A Cost-effective Alternative}},
volume = {2},
year = {2015}
}
@article{Amutha2013,
abstract = {In recent years, the image processing mechanisms are widely used in medical image diagnosis, especially in detection of various tumors. In this paper, we propose a level set-active contour model with minimizer function for lung tumor diagnosis and segmentation. Kernel based non-local neighborhood denoising function is used to get noise free image. Second order histogram based feature extraction is accomplished for classifying the images under normal and abnormal classes. Following tumor detection, exact segmentation of the tumor is effected by level set-active contour modeling with minimized gradient. Experiments demonstrated that our methodology could segment the lung field with pathology of variant forms more precisely. I.},
author = {Amutha, A and Wahidabanu, R S D},
file = {::},
isbn = {9781467348669},
keywords = {ct,enhancement,feature extraction,segmentation},
number = {7},
pages = {1108--1112},
title = {{Lung Tumor Detection and Diagnosis in CT scan Images}},
volume = {6},
year = {2013}
}
@article{Mu,
author = {Mu, Wei and Chen, Zhe},
file = {::},
title = {{Automated measurements of metabolic tumor volume and metabolic parameters in lung PET / CT imaging Automated measurements of metabolic tumor volume and metabolic parameters in lung PET / CT imaging}}
}
@article{Chen2017,
abstract = {Since the discovery of X-rays at the end of the 19(th) century, medical imageology has progressed for 100 years, and medical imaging has become an important auxiliary tool for clinical diagnosis. With the launch of the human genome project (HGP) and the development of various high-throughput detection techniques, disease exploration in the post-genome era has extended beyond investigations of structural changes to in-depth analyses of molecular abnormalities in tissues, organs and cells, on the basis of gene expression and epigenetics. These techniques have given rise to genomics, proteomics, metabolomics and other systems biology subspecialties, including radiogenomics. Radiogenomics is an important revolution in the traditional visually identifiable imaging technology and constitutes a new branch, radiomics. Radiomics is aimed at extracting quantitative imaging features automatically and developing models to predict lesion phenotypes in a non-invasive manner. Here, we summarize the advent and development of radiomics, the basic process and challenges in clinical practice, with a focus on applications in pulmonary nodule evaluations, including diagnostics, pathological and molecular classifications, treatment response assessments and prognostic predictions, especially in radiotherapy.},
author = {Chen, Bojiang and Zhang, Rui and Gan, Yuncui and Yang, Lan and Li, Weimin},
doi = {10.1186/s13014-017-0885-x},
file = {:C$\backslash$:/Users/tauro/Downloads/s13014-017-0885-x.pdf:pdf},
isbn = {1748-717X (Electronic) 1748-717X (Linking)},
issn = {1748717X},
journal = {Radiation Oncology},
keywords = {Lung cancer,Phenotype,Pulmonary nodule,Radiomics},
number = {1},
pages = {1--8},
pmid = {28915902},
publisher = {Radiation Oncology},
title = {{Development and clinical application of radiomics in lung cancer}},
volume = {12},
year = {2017}
}
@article{Jawahar2014,
author = {Jawahar, C. V. and Shan, Shiguang},
doi = {10.1007/978-3-319-16634-6},
file = {:C$\backslash$:/Users/tauro/Downloads/943717.pdf:pdf},
isbn = {9783319166339},
issn = {16113349},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
pages = {109--121},
title = {{Computer vision - ACCV 2014 workshops: Singapore, Singapore, november 1-2, 2014 revised selected papers, Part III}},
volume = {9010},
year = {2014}
}
@article{Wasserman2015,
author = {Wasserman, Hillary},
file = {:C$\backslash$:/Users/tauro/Downloads/2017-WCLC-Fact-Sheet-Lung-Cancer-Final.pdf:pdf},
journal = {American Cancer Society},
keywords = {American Cancer Society},
pages = {19--21},
title = {{Cancer Facts and Statistics}},
url = {http://www.cancer.org/research/cancerfactsstatistics/cancerfactsfigures2015/index},
year = {2015}
}
@article{AlMohammad2017,
abstract = {Lung cancer is the leading cause of cancer-related death worldwide; however, early diagnosis of lung cancer leads to higher survival rates. The National Lung Screening Trial (NLST) demonstrated that scanning with low-dose computed tomography (LDCT) led to a 20{\%} reduction in mortality rate in a high-risk population. This paper covers new developments in screening eligibility criteria and the possible benefits and the harm of screening with CT. To make the screening process more feasible and help reduce the rate of missed lung nodules, computer-aided detection (CAD) has been introduced to assist radiologists in lung nodule detection. The aim of this paper is to review how CAD works, its performance in lung nodule detection, and the factors that influence its performance. This paper also aims to investigate the effect of different types of CAD on CT in lung nodule detection and the effect of CAD on radiologists' decision outcomes.},
author = {{Al Mohammad}, B. and Brennan, P. C. and Mello-Thoms, C.},
doi = {10.1016/j.crad.2017.01.002},
file = {:C$\backslash$:/Users/tauro/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Al Mohammad, Brennan, Mello-Thoms - 2017 - A review of lung cancer screening and the role of computer-aided detection.pdf:pdf},
isbn = {1365-229X (Electronic)
0009-9260 (Linking)},
issn = {1365229X},
journal = {Clinical Radiology},
number = {6},
pages = {433--442},
pmid = {28185635},
publisher = {The Royal College of Radiologists},
title = {{A review of lung cancer screening and the role of computer-aided detection}},
url = {http://dx.doi.org/10.1016/j.crad.2017.01.002},
volume = {72},
year = {2017}
}
@book{Indicators2017,
abstract = {This book includes key environmental indicators endorsed by OECD Environment Ministers and major environmental indicators from the OECD Core Set. These indicators reflect environmental progress made since the early 1990s and thus contribute to measuring environmental performance. Organised by issues such as climate change, air pollution, biodiversity, waste or water resources, they provide essential information for all those interested in the environment and in sustainable development.},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Indicators, Oecd},
doi = {10.1787/health_glance-2017-en},
eprint = {arXiv:1011.1669v3},
file = {:C$\backslash$:/Users/tauro/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Indicators - 2017 - Health at a Glance 2017.pdf:pdf},
isbn = {9789264280397},
issn = {03044130},
pmid = {12870},
title = {{Health at a Glance 2017}},
url = {http://www.oecd-ilibrary.org/social-issues-migration-health/health-at-a-glance-2017{\_}health{\_}glance-2017-en},
year = {2017}
}
@misc{CancerResearchUK,
author = {{Cancer Research UK}},
file = {:C$\backslash$:/Users/tauro/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/3eb2d1b1ac34a3dbde8572de1d1ad6625e107ea6.html:html},
title = {{Lung-Cancer @ Www.Cancerresearchuk.Org}},
url = {http://www.cancerresearchuk.org/health-professional/cancer-statistics/statistics-by-cancer-type/lung-cancer}
}
@article{Gillies2016,
abstract = {radiomics In the past decade, the field of medical image analysis has grown exponentially, with an increased number of pattern recognition tools and an increase in data set sizes. These advances have facilitated the development of processes for high-throughput extraction of quantitative features that result in the conversion of images into mineable data and the subsequent analysis of these data for decision support; this practice is termed radiomics. This is in contrast to the traditional practice of treating medical images as pictures intended solely for visual interpretation. Radiomic data contain first-, second-, and higher-order statistics. These data are combined with other patient data and are mined with sophisticated bioinformatics tools to develop models that may potentially improve diagnostic, prognostic, and predictive accuracy. Because radiomics analyses are intended to be conducted with standard of care images, it is conceivable that conversion of digital images to mineable data will eventually become routine practice. This report describes the process of radiomics, its challenges, and its potential power to facilitate better clinical decision making, particularly in the care of patients with cancer.},
author = {Gillies, Robert J. and Kinahan, Paul E. and Hricak, Hedvig},
doi = {10.1148/radiol.2015151169},
file = {:C$\backslash$:/Users/tauro/Downloads/Radiomics{\_} images are more than pictures, they are data.pdf:pdf},
isbn = {0033-8419},
issn = {0033-8419},
journal = {Radiology},
number = {2},
pages = {563--577},
pmid = {26579733},
title = {{Radiomics: Images Are More than Pictures, They Are Data}},
url = {http://pubs.rsna.org/doi/10.1148/radiol.2015151169},
volume = {278},
year = {2016}
}
@misc{University,
author = {of Tartu, University},
title = {{Image Processing @ sisu.ut.ee}},
url = {https://sisu.ut.ee/imageprocessing/book/1},
urldate = {2018-08-01}
}
@article{Hussein2017,
abstract = {Characterization of lung nodules as benign or malignant is one of the most important tasks in lung cancer diagnosis, staging and treatment planning. While the variation in the appearance of the nodules remains large, there is a need for a fast and robust computer aided system. In this work, we propose an end-to-end trainable multi-view deep Convolutional Neural Network (CNN) for nodule characterization. First, we use median intensity projection to obtain a 2D patch corresponding to each dimension. The three images are then concatenated to form a tensor, where the images serve as different channels of the input image. In order to increase the number of training samples, we perform data augmentation by scaling, rotating and adding noise to the input image. The trained network is used to extract features from the input image followed by a Gaussian Process (GP) regression to obtain the malignancy score. We also empirically establish the significance of different high level nodule attributes such as calcification, sphericity and others for malignancy determination. These attributes are found to be complementary to the deep multi-view CNN features and a significant improvement over other methods is obtained.},
archivePrefix = {arXiv},
arxivId = {1703.00645},
author = {Hussein, Sarfaraz and Gillies, Robert and Cao, Kunlin and Song, Qi and Bagci, Ulas},
doi = {10.1109/ISBI.2017.7950686},
eprint = {1703.00645},
file = {:C$\backslash$:/Users/tauro/Downloads/drive-download-20180728T141600Z-001/1703.00645.pdf:pdf},
isbn = {9781509011711},
issn = {19458452},
journal = {Proceedings - International Symposium on Biomedical Imaging},
keywords = {Computed tomography,Computer-aided diagnosis,Deep learning,Lung cancer,Pulmonary nodule},
pages = {1007--1010},
title = {{TumorNet: Lung nodule characterization using multi-view Convolutional Neural Network with Gaussian Process}},
year = {2017}
}

@misc{cnn,
title = {Convolutional neural networks are fantastic for visual recognition tasks.},
 year = 2018,
url = {https://cv-tricks.com/cnn/understand-resnet-alexnet-vgg-inception/},
urldate = {2018-08-15}
}
@misc{data,
author = {Goldgof Dmitry, Hall Lawrence, Hawkins Samuel, Schabath Matthew, Stringfield Olya, Garcia Alberto, Gillies Robert},
title = {Data From QIN LUNG CT. The Cancer Imaging Archive. },
 year= 2015,
url = {http://doi.org/10.7937/K9/TCIA.2015.NPGZYZBZ},
urldate = {2018-08-01}
}
@misc{QIN,
author = {Jayashree Kalpathy-Cramer, Sandy Napel, Dmitry Goldgof, Binsheng Zhao},
title = {QIN multi-site collection of Lung CT data with Nodule Segmentations},
 year= 2015,
url = {http://dx.doi.org/10.7937/K9/TCIA.2015.1BUVFJR7},
urldate = {2018-08-01}
}
@Article{Clark2013,
author="Clark, Kenneth
and Vendt, Bruce
and Smith, Kirk
and Freymann, John
and Kirby, Justin
and Koppel, Paul
and Moore, Stephen
and Phillips, Stanley
and Maffitt, David
and Pringle, Michael
and Tarbox, Lawrence
and Prior, Fred",
title="The Cancer Imaging Archive (TCIA): Maintaining and Operating a Public Information Repository",
journal="Journal of Digital Imaging",
year="2013",
month="Dec",
day="01",
volume="26",
number="6",
pages="1045--1057",
abstract="The National Institutes of Health have placed significant emphasis on sharing of research data to support secondary research. Investigators have been encouraged to publish their clinical and imaging data as part of fulfilling their grant obligations. Realizing it was not sufficient to merely ask investigators to publish their collection of imaging and clinical data, the National Cancer Institute (NCI) created the open source National Biomedical Image Archive software package as a mechanism for centralized hosting of cancer related imaging. NCI has contracted with Washington University in Saint Louis to create The Cancer Imaging Archive (TCIA)---an open-source, open-access information resource to support research, development, and educational initiatives utilizing advanced medical imaging of cancer. In its first year of operation, TCIA accumulated 23 collections (3.3 million images). Operating and maintaining a high-availability image archive is a complex challenge involving varied archive-specific resources and driven by the needs of both image submitters and image consumers. Quality archives of any type (traditional library, PubMed, refereed journals) require management and customer service. This paper describes the management tasks and user support model for TCIA.",
issn="1618-727X",
doi="10.1007/s10278-013-9622-7",
url="https://doi.org/10.1007/s10278-013-9622-7"
}
@misc{overfitting,
title = {Improve Neural Network Generalization and Avoid Overfitting},
url = {https://it.mathworks.com/help/nnet/ug/improve-neural-network-generalization-and-avoid-overfitting.html},
urldate = {2018-08-30}
}
@article{JMLR:v15:srivastava14a,
  author  = {Nitish Srivastava and Geoffrey Hinton and Alex Krizhevsky and Ilya Sutskever and Ruslan Salakhutdinov},
  title   = {Dropout: A Simple Way to Prevent Neural Networks from Overfitting},
  journal = {Journal of Machine Learning Research},
  year    = {2014},
  volume  = {15},
  pages   = {1929-1958},
  }
  @article{article,
author = {Altenberger, Felix and Lenz, Claus},
year = {2018},
month = {03},
pages = {},
title = {A Non-Technical Survey on Deep Convolutional Neural Network Architectures}
}
@misc{vggnet,
url={https://codebox.net/convnetdesigners/main.html}
}
@article{vgg,
  author    = {Karen Simonyan and
               Andrew Zisserman},
  title     = {Very Deep Convolutional Networks for Large-Scale Image Recognition},
  journal   = {CoRR},
  volume    = {abs/1409.1556},
  year      = {2014},
  url       = {http://arxiv.org/abs/1409.1556},
  archivePrefix = {arXiv},
  eprint    = {1409.1556},
  timestamp = {Mon, 13 Aug 2018 16:46:51 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/SimonyanZ14a},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}
@INPROCEEDINGS{Lecun,
    author = {Yann Lecun and LÃ©on Bottou and Yoshua Bengio and Patrick Haffner},
    title = {Gradient-based learning applied to document recognition},
    booktitle = {Proceedings of the IEEE},
    year = {1998},
    pages = {2278--2324}
}